{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephenkiilu/Natural-Language-Processing-NLP-Week_3/blob/main/Stephen_Kiilu_ammi_dnlp_lab_machine_reading_answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzAMazBhyO7O"
      },
      "source": [
        "# AMMI Deep Natural Language Processing: Lab 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A_H1oDhrSFgF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2oBLu8PyV1V"
      },
      "source": [
        "## 0. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHed26lWcGwQ"
      },
      "source": [
        "**All questions should be answered in the separate google form to be graded.**\n",
        "\n",
        "\n",
        "In this lab we will train neural networks on the bAbI tasks using ParlAI framework.  \n",
        "This lab can be run both in google colab or on your computer.   \n",
        "\n",
        "We will cover the following:\n",
        "0. Introduction\n",
        "    - Introduction to ParlAI and installation\n",
        "    - Introduction to the bAbI tasks\n",
        "1. Exploring the data:\n",
        "    - Compute some statistics (number of examples in train, valid, test, size of examples...)\n",
        "    - Look at some examples\n",
        "2. Choose the appropriate metrics\n",
        "3. Baselines\n",
        "    - Random baseline\n",
        "    - Majority class baseline\n",
        "    - Information retrieval baseline\n",
        "4. More elaborate models\n",
        "   - Generative model: Seq2Seq\n",
        "   - Ranking model: Memory Network\n",
        "5. To go further\n",
        "    - Additional ideas to try if you want to dig deeper\n",
        "\n",
        "### ParlAI\n",
        "[ParlAI](https://github.com/facebookresearch/ParlAI/blob/master/README.md) (pronounced “par-lay”) is a framework for dialogue AI research, implemented in Python.\n",
        "\n",
        "Its goal is to provide researchers:\n",
        "\n",
        "* a unified framework for sharing, training and testing dialogue models\n",
        "* many popular datasets available all in one place -- from open-domain chitchat to visual question answering.\n",
        "* a wide set of reference models -- from retrieval baselines to Transformers.\n",
        "* seamless integration of Amazon Mechanical Turk for data collection and human evaluation\n",
        "* integration with Facebook Messenger to connect agents with humans in a chat interface\n",
        "\n",
        "Documentation can be found [here](https://www.parl.ai/docs/index.html), some of this tutorial is inspired from the ParlAI documentation so feel free to go back and forth between the notebook and the documentation.\n",
        "\n",
        "\n",
        "### Setup the notebook\n",
        "If using google colab, make sure to use TPU runtime by going to ***Runtime > Change runtime type > Hardware accelerator: TPU > Save***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k8BZE3HJaut"
      },
      "source": [
        "### Install ParlAI\n",
        "\n",
        "Start by installing ParlAI from github. The ParlAI folder will be located in the home directory at `~/ParlAI/`.  \n",
        "*Note: In a jupyter notebook, you can run arbitrary bash commands by prefixing them with a question mark, example: `!echo \"Hello World\"`*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8V7QcnMI7Wk"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/facebookresearch/ParlAI.git ~/ParlAI\n",
        "!cd ~/ParlAI && git checkout 6bd0e58692b3fd3a13b5f654944525ac1b7cd8e3\n",
        "!cd ~/ParlAI; python3 setup.py develop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !echo \"Hello World\""
      ],
      "metadata": {
        "id": "s60JH0JsSSmv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJDOC-zsL3wR"
      },
      "source": [
        "Most of the scripts that we will use in ParlAI are located in the `~/ParlAI/examples` directory.  \n",
        "Let's have a first glance at the scripts available, we will come back to them later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bIMjwxKrLm36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b34b5b56-7eb0-42be-9025-fc8697413910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_train.py\t       eval_model.py\t\t remote.py\n",
            "build_dict.py\t       extract_image_feature.py  seq2seq_train_babi.py\n",
            "build_pytorch_data.py  interactive.py\t\t train_model.py\n",
            "display_data.py        profile_train.py\n",
            "display_model.py       README.md\n"
          ]
        }
      ],
      "source": [
        "!ls ~/ParlAI/examples/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4UnbCdcqHPu"
      },
      "source": [
        "### The bAbI tasks\n",
        "Many datasets and tasks are included in ParlAI, we will focus on the bAbI tasks.\n",
        "The bAbI tasks are 20 synthetic tasks that each test a unique aspect of text and reasoning, and hence test different capabilities of learning models from [Weston et al. ‘16](http://arxiv.org/abs/1502.05698).\n",
        "\n",
        "---\n",
        "**Question 0.**  \n",
        "Open the bAbI [paper](https://arxiv.org/pdf/1502.05698.pdf) and read the abstract  and section: *\"3 The Tasks\"* (until paragraph **Two or Three Supporting Facts**,  included).  \n",
        "- **0.a.** Explain in your own words the motivations behind these tasks (in 2-3 sentences).\n",
        "\n",
        "*ANSWER IN GOOGLE FORM*\n",
        "\n",
        "---\n",
        "\n",
        "These tasks can be downloaded and used directly from ParlAI.  \n",
        "We will focus on tasks 1, 2 and 3, see examples below:\n",
        "\n",
        "\n",
        "**Task 1: Single Supporting Fact**  \n",
        "Mary went to the bathroom.  \n",
        "John moved to the hallway.  \n",
        "Mary travelled to the office.  \n",
        "Where is Mary?  \n",
        "**Answer: office**  \n",
        "\n",
        "\n",
        "**Task 2: Two Supporting Facts**  \n",
        "John is in the playground.  \n",
        "John picked up the football.  \n",
        "Bob went to the kitchen.  \n",
        "Where is the football?  \n",
        "**Answer: playground**\n",
        "\n",
        "\n",
        "**Task 3: Three Supporting Facts**  \n",
        "John picked up the apple.  \n",
        "John went to the office.  \n",
        "John went to the kitchen.  \n",
        "John dropped the apple.   \n",
        "Where was the apple before the kitchen?  \n",
        "**Answer: office**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6IZA9r0MjBd"
      },
      "source": [
        "## 1. Exploring the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Cc-Si6SyatK"
      },
      "source": [
        "First we need to download the data, we will use the `build_dict.py` as a dummy task to download the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAEH7xUXtxFj"
      },
      "outputs": [],
      "source": [
        "# Download the data silently\n",
        "!python3 ~/ParlAI/examples/build_dict.py --task babi:task1k:1 --dict-file /tmp/babi1.dict\n",
        "# Print a few examples\n",
        "!head -n 30 ~/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_train.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbc5n2xpPnsb"
      },
      "source": [
        "The bAbI tasks were downloaded in `~/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-nosf/`\n",
        "\n",
        "In bAbI the data is organised as follows:\n",
        "- **Dialog turn**: A dialog turn is a single utterance / statement. Each line in the file corresponds to one dialog turn.   \n",
        "  Example: *\"John went to the office.\"*\n",
        "- **Sample (question)**: Every few dialog turns, a question can be asked that the model has to answer, this consitute a sample.  The question is followed by its ground truth answer, separated by a tab.\n",
        "  Example: *\"Where is John? `<tab>` bathroom\"*\n",
        "- **Episode**: a sequence of ordered coherent dialog turns that are related to each other form an episode. Each new episode is independant of the others. Each line starts with the dialog turn number in the current episode.\n",
        "\n",
        "\n",
        "---\n",
        "**Question 1.**\n",
        "- **1.a.** Look at the training file of task 1 (`~/ParlAI/data/bAbI/tasks_1-20_v1-2/en/qa1_train.txt`) and compute the following information:\n",
        "  - Number of episodes\n",
        "  - Number of  samples (questions)\n",
        "  - Number of dialog turns per episode\n",
        "  - How many different answers are there in the train set? How many times does each appear? (*hint: Use a python [counter](https://docs.python.org/3/library/collections.html#collections.Counter)*)\n",
        "  - How many unique words appear in the training set? How many time does each appear? (*hint: Use the Counter `most_common()` method*)\n",
        "\n",
        "*Print the answer in the following code cell*\n",
        "  \n",
        "  ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk7B40wOf8nU"
      },
      "outputs": [],
      "source": [
        "# FILL THIS CELL\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "task_1_train_path = '/root/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_train.txt'\n",
        "with open(task_1_train_path, 'r') as f:\n",
        "    # FILL CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SOLUTION\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "task_1_train_path = '/root/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_train.txt'\n",
        "n_episodes = 0\n",
        "n_questions = 0\n",
        "n_total_dialog_turns = 0\n",
        "possible_answers = Counter()\n",
        "vocabulary = Counter()\n",
        "with open(task_1_train_path, 'r') as f:\n",
        "    for line in f:\n",
        "        # Each line starts with an integer giving the dialog turn in the current episode.\n",
        "        # Each episode contains dialog turns with questions (with the answer next to it separated by a tab)\n",
        "        line = line.strip('\\n')\n",
        "        dialog_turn = int(line.split(' ')[0])\n",
        "        # print(  dialog_turn )\n",
        "        if dialog_turn == 1:\n",
        "            n_episodes += 1\n",
        "        # Remove the dialog turn number\n",
        "        line = ' '.join(line.split(' ')[1:])\n",
        "        fields = line.split('\\t')\n",
        "        if len(fields) > 1:\n",
        "            n_questions += 1\n",
        "            possible_answers.update([fields[1]])\n",
        "        vocabulary.update(fields[0].split(' '))\n",
        "        n_total_dialog_turns += 1\n",
        "print(f'Number of episodes: {n_episodes}')\n",
        "print(f'Number of questions: {n_questions}')\n",
        "print(f'Number of dialog turns per episode: {n_total_dialog_turns/n_episodes}')\n",
        "print(f'Possible answers: {possible_answers} ({len(possible_answers)})')\n",
        "print(f'Accuracy of a random model: {1/len(possible_answers):.4f}')\n",
        "print(f'Vocabulary size: {len(vocabulary)}')\n",
        "print(f'Most common words: {vocabulary.most_common()}')"
      ],
      "metadata": {
        "id": "UJ7f7niGYsDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c19860-8610-49d4-a985-40d8967ac811"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of episodes: 1800\n",
            "Number of questions: 9000\n",
            "Number of dialog turns per episode: 15.0\n",
            "Possible answers: Counter({'bathroom': 1564, 'hallway': 1517, 'garden': 1508, 'bedroom': 1473, 'kitchen': 1471, 'office': 1467}) (6)\n",
            "Accuracy of a random model: 0.1667\n",
            "Vocabulary size: 24\n",
            "Most common words: [('to', 18000), ('the', 18000), ('Where', 9000), ('is', 9000), ('', 9000), ('went', 7225), ('Mary', 4535), ('Sandra', 4502), ('John', 4484), ('Daniel', 4479), ('journeyed', 3620), ('travelled', 3582), ('back', 3581), ('moved', 3573), ('bathroom.', 3070), ('hallway.', 3045), ('garden.', 2982), ('kitchen.', 2981), ('office.', 2963), ('bedroom.', 2959), ('John?', 2299), ('Mary?', 2265), ('Sandra?', 2244), ('Daniel?', 2192)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FILL THIS CELL\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "task_1_train_path = '/root/ParlAI/data/bAbI/tasks_1-20_v1-2/en-valid-10k-nosf/qa1_train.txt'\n",
        "episodes=0\n",
        "questions=0\n",
        "train=[]\n",
        "possible_ans= Counter()\n",
        "answers=[]\n",
        "total=0\n",
        "\n",
        "with open(task_1_train_path, 'r') as f:\n",
        "  for sentence in f:\n",
        "    total+=1\n",
        "    # print(sentence)\n",
        "    if '\\t' in sentence:\n",
        "      questions+=1\n",
        "    sens=sentence.split()[0]\n",
        "    if sens=='1':\n",
        "      episodes+=1\n",
        "    sentences = sentence.translate(str.maketrans('', '', string.punctuation)).split()\n",
        "    train.append(sentences[1:])\n",
        "    if '?' in sentence:\n",
        "      answer=sentence.split()[-1]\n",
        "      answers.append(answer)\n",
        "for word in answers:\n",
        "  possible_ans[word]+=1\n",
        "\n",
        "vocab=list(set([t for ts in train for t in ts]))\n",
        "     \n",
        "print(f'Total number of Dialog turns: {total}')\n",
        "print(f'The number of questions is: {questions}')\n",
        "print(f'The number of episodes is: {episodes}')\n",
        "print(f'Number of dialog turns per episode: {total//episodes}')\n",
        "print(f'Accuracy of a random model: {1/len(possible_ans):.4f}')\n",
        "print(f'Vocabulary size: {len(vocab)}')\n",
        "print(f'Possible answers: {possible_ans}' )\n",
        "\n",
        "    # FILL CODE HERE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8whjHKCR4p7",
        "outputId": "d3aefb75-1a1d-4ed2-d1b1-44f73d7b982c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of Dialog turns: 27000\n",
            "The number of questions is: 9000\n",
            "The number of episodes is: 1800\n",
            "Number of dialog turns per episode: 15\n",
            "Accuracy of a random model: 0.1667\n",
            "Vocabulary size: 19\n",
            "Possible answers: Counter({'bathroom': 1564, 'hallway': 1517, 'garden': 1508, 'bedroom': 1473, 'kitchen': 1471, 'office': 1467})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNYNtDHiuVq8"
      },
      "source": [
        "\n",
        "Use the appropriate script from the `~/ParlAI/examples/` to take a quick look at examples of the first bAbI task.  \n",
        "Does the number of episodes and examples fit what you computed before? (*hint: you can use the argument `--task babi:task1k:1` to select the first babi task*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6HlIvzGgKv2"
      },
      "outputs": [],
      "source": [
        "# FILL THIS CELL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SOLUTION\n",
        "!python3 ~/ParlAI/examples/display_data.py --task babi:task10k:1"
      ],
      "metadata": {
        "id": "vIihrDocYur_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TovRmKOA858i"
      },
      "source": [
        "## 2. Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9NV_vBlPSWP"
      },
      "source": [
        "The bAbI task 1 expects single word answers among a small set of possible answers.\n",
        "\n",
        "\n",
        "---\n",
        "**Question 2**  \n",
        "- **2.a.** Which metrics do you think are appropriate for evaluating a model on this task?   \n",
        "-  **2.b.**  What are their respective strengths?  \n",
        "-  **2.c.** When do they fail? (find specific examples)  \n",
        "\n",
        "\n",
        "*ANSWER IN GOOGLE FORM* \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_MZKCTW6fh9"
      },
      "source": [
        "## 3. Baseline\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSexIY71yiD6"
      },
      "source": [
        "We now have a clearer idea of the data distribution and the metrics that we can use.  \n",
        "The next step is to start solving the tasks with a simple baseline. This will allow us to compare more elaborate models agains this baseline.  \n",
        "Here are a few classical baselines:\n",
        "- **Random model**: The model answers randomly among the set of possible answers for each question\n",
        "-  **Majority class**: The model always answers with the most frequent answer in the training set (majority class)\n",
        "\n",
        "We are going to reimplement these own baselines.  \n",
        "Implementing a new model in ParlAI is detailed in the [tutorial](http://parl.ai/static/docs/seq2seq_tutorial.html) but for our simple baselines, we will only need to inherit the [Agent](https://github.com/facebookresearch/ParlAI/blob/6d246842d3f4e941dd3806f3d9fa62f607d48f59/parlai/core/agents.py#L50) class and override the `act()` method.\n",
        "\n",
        "---\n",
        "**Question 3**  \n",
        "- **3.a.** What would be the accuracy of a model that choses a random answer among the set of possible answers for each question? \n",
        "\n",
        "*ANSWER IN GOOGLE FORM*\n",
        "\n",
        "---\n",
        "\n",
        "*Note: the `%%writefile` magic command in jupyter writes the content of the cell to a file at the given path.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9ahmFL0Rk6g1"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/ParlAI/parlai/agents/baseline/\n",
        "!touch ~/ParlAI/parlai/agents/baseline/random.py\n",
        "!touch ~/ParlAI/parlai/agents/baseline/majorityclass.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZLM7DtkkJN1"
      },
      "source": [
        "- **3.b.**  Design a baseline that answers a random word in the set of possible answer (run it multiple time to observe variance in results)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Zx4emBSPjmE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7ba28a-1352-441e-c01d-e0a33fb43c0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /root/ParlAI/parlai/agents/baseline/random.py\n"
          ]
        }
      ],
      "source": [
        "# FILL THIS CELL\n",
        "%%writefile ~/ParlAI/parlai/agents/baseline/random.py\n",
        "import random\n",
        "\n",
        "from parlai.core.torch_agent import Agent\n",
        "\n",
        "\n",
        "class RandomAgent(Agent):\n",
        "  \n",
        "    def act(self):\n",
        "        # FILL CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SOLUTION\n",
        "%%writefile ~/ParlAI/parlai/agents/baseline/random.py\n",
        "import random\n",
        "\n",
        "from parlai.core.torch_agent import Agent\n",
        "\n",
        "\n",
        "class RandomAgent(Agent):\n",
        "  \n",
        "    def act(self):\n",
        "        if 'label_candidates' not in self.observation:\n",
        "            return\n",
        "        candidates = list(self.observation['label_candidates'])\n",
        "        index = random.randrange(len(candidates))\n",
        "        reply = {'text': candidates[index]}\n",
        "        return reply"
      ],
      "metadata": {
        "id": "vK1Nwf2sYyAC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3e1ca4-ed0d-4b69-90be-1f1db2b837ed"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /root/ParlAI/parlai/agents/baseline/random.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iQRPYGnH75D-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dMOWxgVj1Joz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56e7156-cd10-43eb-aefe-3a3ffe49d8fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'exs': 1000, 'accuracy': 0.183, 'f1': 0.183, 'bleu': 1.83e-10}\n"
          ]
        }
      ],
      "source": [
        "!python3 ~/ParlAI/examples/eval_model.py -t babi:task10k:1 -m baseline/random | grep accuracy -A 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVs3pOKE2-WE"
      },
      "outputs": [],
      "source": [
        "!python3 ~/ParlAI/examples/display_model.py -t babi:task10k:1 -m baseline/random -n 10 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UnE4oVakR4k"
      },
      "source": [
        "- **3.c.**  Design a baseline that answers the most common answer every time (majority class baseline)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hHIV2NUzGzQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0beb60-9cc8-42a0-fb4a-aaf09284a969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /root/ParlAI/parlai/agents/baseline/majorityclass.py\n"
          ]
        }
      ],
      "source": [
        "# FILL THIS CELL\n",
        "%%writefile ~/ParlAI/parlai/agents/baseline/majorityclass.py\n",
        "import random\n",
        "\n",
        "from parlai.core.torch_agent import Agent\n",
        "\n",
        "\n",
        "class MajorityclassAgent(Agent):\n",
        "  \n",
        "    def act(self):\n",
        "        # FILL CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SOLUTION\n",
        "%%writefile ~/ParlAI/parlai/agents/baseline/majorityclass.py\n",
        "import random\n",
        "\n",
        "from parlai.core.torch_agent import Agent\n",
        "\n",
        "\n",
        "class MajorityclassAgent(Agent):\n",
        "  \n",
        "    def act(self):\n",
        "        if 'label_candidates' not in self.observation:\n",
        "            return\n",
        "        reply = {'text': 'bathroom'}\n",
        "        return reply"
      ],
      "metadata": {
        "id": "RTdfx6fAY0_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d35e812-9c8b-400a-98c6-41b0a550266b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /root/ParlAI/parlai/agents/baseline/majorityclass.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "U34z6bx0lJV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055169d3-6cf6-4a22-9b28-416581d89763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'exs': 1000, 'accuracy': 0.169, 'f1': 0.169, 'bleu': 1.69e-10}\n"
          ]
        }
      ],
      "source": [
        "!python3 ~/ParlAI/examples/eval_model.py -t babi:task10k:1 -m baseline/majorityclass | grep accuracy -A 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8LHkfUS3AL0"
      },
      "outputs": [],
      "source": [
        "!python3 ~/ParlAI/examples/display_model.py -t babi:task10k:1 -m baseline/majorityclass -n 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOW4ZTSekWt9"
      },
      "source": [
        "---\n",
        "- **3.d.**  In which cases would the majority class baseline be better than the random baseline?\n",
        "\n",
        "*ANSWER IN GOOGLE FORM*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "layL9aTK_D1a"
      },
      "source": [
        "Another slightly more advanced baseline is implemented in ParlAI: the information retrieval baseline (`ir_baseline`)\n",
        "\n",
        "---\n",
        "- **3.e.** Look at the [implementation](https://github.com/facebookresearch/ParlAI/blob/53ea58acf389bffc79c85c43bcdd848eecdcecb4/parlai/agents/ir_baseline/ir_baseline.py#L211) of the IR baseline and explain in a few lines how it works (*hint: look at the following methods `act()` `rank_candidates()`  `score_match()`*)  \n",
        "\n",
        "*ANSWER IN GOOGLE FORM*\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKo6zJHwksKA"
      },
      "source": [
        "- **3.f.** Use the IR baseline and compare its with one of your baselines (random and/or majority) on bAbI tasks 1, 2 and 3.  \n",
        "    (*hint: you can use `!python3 ... -t babi:task1-k:{i+1}` syntax to substitute the task number in a bash command from jupyter*)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzBAEWP7k10U"
      },
      "outputs": [],
      "source": [
        "# FILL THIS CELL\n",
        "for i in range(3):\n",
        "    print(f'~ Task {i+1} ~')\n",
        "    # FILL CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SOLUTION\n",
        "for i in range(3):\n",
        "    print(f'~ Task {i+1} ~')\n",
        "    print('Majority class baseline:')\n",
        "    !python3 ~/ParlAI/examples/eval_model.py -t babi:task10k:{i+1} -m baseline/majorityclass | grep accuracy\n",
        "    print('IR baseline:')\n",
        "    !python3 ~/ParlAI/examples/eval_model.py -t babi:task10k:{i+1} -m ir_baseline | grep accuracy"
      ],
      "metadata": {
        "id": "XJn7d2nOY3TA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4afb651-8c59-4fca-fde5-ba00f8bbd3dd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~ Task 1 ~\n",
            "Majority class baseline:\n",
            "{'exs': 1000, 'accuracy': 0.169, 'f1': 0.169, 'bleu': 1.69e-10}\n",
            "IR baseline:\n",
            "{'exs': 1000, 'accuracy': 0.465, 'f1': 0.465, 'hits@1': 0.465, 'hits@5': 0.961, 'hits@10': 1.0, 'hits@100': 1.0, 'bleu': 4.65e-10}\n",
            "~ Task 2 ~\n",
            "Majority class baseline:\n",
            "{'exs': 1000, 'accuracy': 0.17, 'f1': 0.17, 'bleu': 1.7e-10}\n",
            "IR baseline:\n",
            "{'exs': 1000, 'accuracy': 0.284, 'f1': 0.284, 'hits@1': 0.284, 'hits@5': 0.9, 'hits@10': 1.0, 'hits@100': 1.0, 'bleu': 2.84e-10}\n",
            "~ Task 3 ~\n",
            "Majority class baseline:\n",
            "{'exs': 1000, 'accuracy': 0.203, 'f1': 0.203, 'bleu': 2.03e-10}\n",
            "IR baseline:\n",
            "{'exs': 1000, 'accuracy': 0.132, 'f1': 0.132, 'hits@1': 0.132, 'hits@5': 0.836, 'hits@10': 1.0, 'hits@100': 1.0, 'bleu': 1.32e-10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZGFSbEwJdvx"
      },
      "source": [
        "## 4. More elaborate models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj7onBcoyoZz"
      },
      "source": [
        "We can now continue to more elaborate models and evaluate their performance in perspective to the baselines.\n",
        "We will use the `~/ParlAI/examples/train_model.py` script. Let's first get a glance at its arguments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZa5Xl5Bxxxe"
      },
      "outputs": [],
      "source": [
        "!python3 ~/ParlAI/examples/train_model.py --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2apZUNj6JrS"
      },
      "source": [
        "We can train two types of models:\n",
        "- **Generative models**: The model generates an answer from its vocabulary.\n",
        "- **Ranking models**: The model is given a list of possible answers and has to choose the correct answer. This is much easier for the model since the list of possible answers is often way smaller than the size of the vocabulary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdBwoP2K36DH"
      },
      "source": [
        "### Generative model: seq2seq with attention\n",
        "\n",
        "The generative model we are going to train is a sequence to sequence model with attention based on [Sustskever et al. 2014](https://arxiv.org/abs/1409.3215) and [Bahdanau et al. 2014](https://arxiv.org/abs/1409.0473).\n",
        "      \n",
        "- **4.a.** Briefly explain how attention works in sequence to sequence neural networks.\n",
        "- **4.b.** Do you think attention is useful for the babi tasks? How would you verify it experimentally?\n",
        "\n",
        "*ANSWER IN GOOGLE FORM*\n",
        "\n",
        "---\n",
        "- **4.c.** Train a seq2seq on bAbI task 1 (10k) and compare its results to the baselines.\n",
        "   (*hint: for faster training use the following arguments `--batchsize 32 --numthreads 1 --num-epochs 5 --hiddensize 64 --embeddingsize 64 --numlayers 1 --decoder shared`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIpwQj4NpY5s"
      },
      "outputs": [],
      "source": [
        "# FILL THIS CELL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SOLUTION\n",
        "!python3 ~/ParlAI/examples/train_model.py --task babi:task10k:1 --model seq2seq  --model-file /tmp/babi_s2s --batchsize 32 --numthreads 1 --num-epochs 5 --hiddensize 64 --embeddingsize 64 --numlayers 1 --decoder shared"
      ],
      "metadata": {
        "id": "GN9TU0SAY6J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvxjgtEHTXFb"
      },
      "outputs": [],
      "source": [
        "!python3 ~/ParlAI/examples/display_model.py --task babi:task10k:1 --model seq2seq --model-file /tmp/babi_s2s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaX_GSktxrz1"
      },
      "source": [
        "### Ranking model: memory network\n",
        "\n",
        "We saw in the class that Memory Networks ([Sukhbaatar et al. 15'](https://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf)) rely on an explicit memory \"database\". this is especially adapted to tasks where a few useful memories are \"hidden\" among distractor memories.  \n",
        "These type of networks worktherefore  especially well for the bAbI tasks by turning the previous dialog turns as memories and the question as the query.  \n",
        "Here is an illustration of how a memory network work:\n",
        "\n",
        "![Memory Network schema](https://raw.githubusercontent.com/louismartin/ammi-2019-bordes-DeepNLP/master/lab1/memory_network.png)\n",
        "\n",
        "\n",
        "---\n",
        "**Question 4**  \n",
        "- **4.d.** Explain how hops work in a memory network (either with words or formulas using the notations of the above figure)\n",
        "- **4.e.** How can a memory network be used to rank multiple candidates?  \n",
        "  (*hint: you can look at the [implementation](https://github.com/facebookresearch/ParlAI/blob/6bd0e58692b3fd3a13b5f654944525ac1b7cd8e3/parlai/agents/memnn/modules.py#L22) of the memory network in ParlAI and especially the `_score()` method. Recall how the IR baseline worked.*)\n",
        "  \n",
        "*ANSWER IN GOOGLE FORM*\n",
        "  \n",
        " \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHICORdji1Cx"
      },
      "source": [
        "\n",
        "- **4.f.** Using the ParlAI implementation, train a memory network on bAbI tasks 1, 2 and 3 (10k) and compare its results with the baselines.  \n",
        "   (*hint: use a 1 thread, a batch size of 32 and 5 epochs*)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "iKeyD3UYsaFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf4d8f9-d850-46be-827f-8c12d46ea287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~ Task 1 ~\n",
            "~ Task 2 ~\n",
            "~ Task 3 ~\n"
          ]
        }
      ],
      "source": [
        "# FILL CELL\n",
        "for i in range(3):\n",
        "    print(f'~ Task {i+1} ~')\n",
        "    # FILL CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SOLUTION\n",
        "for i in range(3):\n",
        "    print(f'~ Task {i+1} ~')\n",
        "    !python3 ~/ParlAI/examples/train_model.py -t babi:task10k:{i+1} -m memnn -mf /tmp/babi{i+1}_memnn -bs 32 -eps 5 | grep \"'accuracy':\""
      ],
      "metadata": {
        "id": "nmQyentFY8gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHH0Wy34o3_W"
      },
      "source": [
        "## 5. To go further"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaNGupqLssUB"
      },
      "source": [
        "If you want to go further you can try to do the following:\n",
        "\n",
        "- Retrieve and plot the attention of the memory network for the different hops along the memories.\n",
        "- For the seq2seq model, can you plot the training loss? The validation loss? Both on the same plot?\n",
        "- Can you show an example of overfitting?\n",
        "- Adapt the seq2seq model for ranking using the [torch ranker tutorial](http://www.parl.ai/static/docs/tutorial_torch_ranker_agent.html)\n",
        "- Try multitasking babi and squad, does it improve the performance? (this will require more GPU power than what is available in google colab)\n",
        "- You can play around with other models and other tasks\n",
        "- Try interfacing ParlAI with [messenger](http://www.parl.ai/static/docs/tutorial_messenger.html )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "N4UnbCdcqHPu"
      ],
      "name": "Stephen Kiilu ammi_dnlp_lab_machine_reading_answers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}